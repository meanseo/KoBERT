{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cpu\n",
      "4.8.2\n",
      "2.7.7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelWithLMHead, PreTrainedTokenizerFast\n",
    "from fastai.text.all import *\n",
    "import re\n",
    "import fastai\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)\n",
    "print( fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:843: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "옛날 옛날 어느 마을에 흥부와 놀부 형제가 왁자지껄 떠들어대며 \"우리 집엔 왜 이렇게 많은 사람들이 모여 사는 거야?\" 하고 묻는다.\n",
      "그런데 그 마을 사람들은 모두 다들 자기네 동네에 살고 있는 사람들이라고 한다.\n",
      "이렇게 해서 우리 마을은 '흥부가 살던 곳'이라는 뜻의 '고향'이 되었다.\n",
      "그리고 이 고향은 바로 지금의 서울 종로구 숭인동이다.\n",
      "숭인동은 원래 종로에서 가장 오래된 주택가였다.\n",
      "1970년대까지만 해도 이곳은 재개발로 인해 헐리고 빈집이 많아졌다.\n",
      "하지만 1980년대 들어 다시 활기를 되찾기 시작했다.\n",
      "당시만 하더라도 이곳에는 낡은 건물들이 많이 남아 있었다.\n",
      "그러나 1990년대 들어서부터는 예전의\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>') \n",
    "model = AutoModelWithLMHead.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "text = \"\"\" 옛날 옛날 어느 마을에 흥부와 놀부 형제가 \"\"\"\n",
    "input_ids = tokenizer.encode(text)\n",
    "gen_ids = model.generate(torch.tensor([input_ids]),\n",
    "                           max_length=128,\n",
    "                           repetition_penalty=2.0,\n",
    "                           pad_token_id=tokenizer.pad_token_id,\n",
    "                           eos_token_id=tokenizer.eos_token_id,\n",
    "                           bos_token_id=tokenizer.bos_token_id,\n",
    "                           use_cache=True\n",
    "                        )\n",
    "generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# from icecream import ic\n",
    "# df = pd.read_csv('./data/book_report_data.csv', index_col=0)\n",
    "# df.drop_duplicates(keep='first', inplace=True, ignore_index=False)\n",
    "# df = df.to_csv('./data/book_report_data.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pykospacing import Spacing\n",
    "\n",
    "with open('./data/book_report_data.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "data=\" \".join(data.split())\n",
    "# print(len(data))\n",
    "data = data.replace('\\n|\\t', ' ')\n",
    "# print(len(data))\n",
    "new_sent = data.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
    "# print(len(new_sent))\n",
    "spacing = Spacing()\n",
    "kospacing_sent = spacing(new_sent) \n",
    "# print(len(kospacing_sent))\n",
    "data = re.sub('[-=+,#/\\:^$@*\\\"※~&%ㆍ』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','', kospacing_sent)\n",
    "# print(len(data))\n",
    "data = re.sub('[a-zA-Z]' , '', data)\n",
    "# print(len(data))\n",
    "\n",
    "\n",
    "# UnicodeDecodeError: 'cp949' codec can't decode byte 0xec in position 20: illegal multibyte sequence\n",
    "# 해당 에러 ->  encoding='utf-8' 넣어 주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#model input output tokenizer\n",
    "class TransformersTokenizer(Transform):\n",
    "   def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "   def encodes(self, x): \n",
    "       toks = self.tokenizer.tokenize(x)\n",
    "       return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
    "   def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))\n",
    "\n",
    "#split data\n",
    "train=data[:int(len(data)*0.9)]\n",
    "test=data[int(len(data)*0.9):]\n",
    "splits = [[0],[1]]\n",
    "\n",
    "#init dataloader\n",
    "tls = TfmdLists([train,test], TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "seq_len = 8,256\n",
    "dls = tls.dataloaders(bs=4, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\torch\\amp\\autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "c:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SuggestedLRs(valley=6.30957365501672e-05)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/50 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='18' class='' max='729' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.47% [18/729 01:37&lt;1:04:29 4.7998]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gpt2 ouput is tuple, we need just one val\n",
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]\n",
    "\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()\n",
    "lr=learn.lr_find()\n",
    "print(lr)\n",
    "learn.fit_one_cycle(50, lr)\n",
    "# learn.fine_tune(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'여행가고 싶어지는 로컬 마트에서 먹고 싶은 음식을 검색으로 찾아다니는 홈페이지이다.이 책의 저자 밥 프록터는 뉴욕에 있는 알베르게 추천여행지 중 한 곳을 약 5년 동안 여유롭게 다녀 온 스팟을 소개한다. 유명 관광지는 물론이고 다양한 볼거리 먹거리와 이색 장소까지 많은 매력을 가진다. 특히 세계적인 호텔 체인도 많이 들어와 있고 현지인과 함께 하는 술집이나 식당 쇼핑 명소도 소개되어 있다.저자는 현지에 친구들이 소개한  에서 만나도록 권유한다힘든 시간들을 어떻게 써야 할 지 막막했는데 지금이라도 이 책을 만나게 된다면 조금은 더 편안한 마음으로 여행을 즐길 수'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt='여행가고 싶어지는'\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp,\n",
    "                           max_length=128,\n",
    "                           pad_token_id=tokenizer.pad_token_id,\n",
    "                           eos_token_id=tokenizer.eos_token_id,\n",
    "                           bos_token_id=tokenizer.bos_token_id,\n",
    "                           repetition_penalty=2.0,\n",
    "                           use_cache=True\n",
    "                          )\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learn.model.save_pretrained(\"./models/kogpt2_bookreport_backup50\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('readvice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f82e657652c1f559b98fb141e76bcce2ec0f3958c3a6000b4409466ee456e5f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
